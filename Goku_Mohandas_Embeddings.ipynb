{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Goku_Mohandas_Embeddings.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Overview\n",
        "While one-hot encoding allows us to preserve the structural information, it does poses two major disadvantages.\n",
        "\n",
        "- linearly dependent on the number of unique tokens in our vocabulary, which is a problem if we're dealing with a large corpus.\n",
        "- representation for each token does not preserve any relationship with respect to other tokens.\n",
        "\n",
        "In this notebook, we're going to motivate the need for embeddings and how they address all the shortcomings of one-hot encoding.\n",
        "\n",
        "> ***The main idea of embeddings is to have fixed length representations for the tokens in a text regardless of the number of tokens in the vocabulary. With one-hot encoding, each token is represented by an array of size vocab_size, but with embeddings, each token now has the shape embed_dim. The values in the representation will are not fixed binary values but rather, changing floating points allowing for fine-grained learned representations.***"
      ],
      "metadata": {
        "id": "hQVXxSYEftgr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Objectives:\n",
        "- Represent tokens in text that capture the intrinsic semantic relationships.\n",
        "###Advantages:\n",
        "- Low-dimensionality while capturing relationships.\n",
        "- Interpretable token representations\n",
        "###Disadvantages:\n",
        "- Can be computationally intensive to precompute.\n",
        "###Miscellaneous:\n",
        "- There are lot's of pretrained embeddings to choose from but you can also train your own from scratch."
      ],
      "metadata": {
        "id": "LsVqzpqJg3S7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Learning embeddings**\n",
        "We can learn embeddings by creating our models in PyTorch but first, we're going to use a library that specializes in embeddings and topic modeling called Gensim."
      ],
      "metadata": {
        "id": "jwjuD56ehKMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\");\n",
        "import numpy as np\n",
        "import re\n",
        "import urllib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwORDYs4g1GO",
        "outputId": "73801783-62f5-4db8-b0c8-6e4715e508a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n"
      ],
      "metadata": {
        "id": "1yg4rBckhRj3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "np.random.seed(SEED)\n"
      ],
      "metadata": {
        "id": "34naIrGDhZNc"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split text into sentences\n",
        "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
        "book = urllib.request.urlopen(url=\"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/harrypotter.txt\")\n",
        "sentences = tokenizer.tokenize(str(book.read()))\n",
        "print (f\"{len(sentences)} sentences\")\n",
        "\n",
        "## Read more about this Punkt tokenizer here\n",
        "## https://stackoverflow.com/questions/35275001/use-of-punktsentencetokenizer-in-nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46AEuaHihbCt",
        "outputId": "37a3c537-93f9-4984-da83-9169a6ffd9d3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12443 sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fsyROTZFkH6C"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "    \"\"\"Conditional preprocessing on our text.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    # Separate into word tokens\n",
        "    text = text.split(\" \")\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "AHEYP7Mthk-1"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess sentences\n",
        "print (sentences[11])\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\n",
        "print (sentences[11])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOs4fQybhp0B",
        "outputId": "61f5d7ff-8172-4835-9201-6b21d6f066a8"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snape nodded, but did not elaborate.\n",
            "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But how do we learn the embeddings the first place? The intuition behind embeddings is that the definition of a token doesn't depend on the token itself but on its context. There are several different ways of doing this:\n",
        "\n",
        "- Given the word in the context, predict the target word (CBOW - continuous bag of words).\n",
        "- Given the target word, predict the context word (skip-gram).\n",
        "- Given a sequence of words, predict the next word (LM - language modeling).\n",
        "\n",
        "All of these approaches involve create data to train our model on. Every word in a sentence becomes the target word and the context words are determines by a window. In the image below (skip-gram), the window size is 1 (1 word to the left and right of the target word). We repeat this for every sentence in our corpus and this results in our training data for the unsupervised task. This in an unsupervised learning technique since we don't have official labels for contexts. The idea is that similar target words will appear with similar contexts and we can learn this relationship by repeatedly training our mode with (context, target) pairs.\n",
        "\n",
        "<img src='https://madewithml.com/static/images/foundations/embeddings/skipgram.png'>\n",
        "\n",
        "We can learn embeddings using any of these approaches above and some work better than others. You can inspect the learned embeddings but the best way to choose an approach is to empirically validate the performance on a supervised task."
      ],
      "metadata": {
        "id": "eneqqdYBnZdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Word2Vec**\n",
        "When we have large vocabularies to learn embeddings for, things can get complex very quickly. Recall that the backpropagation with softmax updates both the correct and incorrect class weights. This becomes a massive computation for every backwards pass we do so a workaround is to use negative sampling which only updates the correct class and a few arbitrary incorrect classes (NEGATIVE_SAMPLING=20). We're able to do this because of the large amount of training data where we'll see the same word as the target class multiple times."
      ],
      "metadata": {
        "id": "AU3epWApp-RK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "id": "GR3V8aw-hx1Q"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "WINDOW = 5\n",
        "MIN_COUNT = 3 # Ignores all words with total frequency lower than this\n",
        "SKIP_GRAM = 1 # 0 = CBOW\n",
        "NEGATIVE_SAMPLING = 20\n"
      ],
      "metadata": {
        "id": "iJssbQieq0VJ"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "w2v = Word2Vec(\n",
        "    sentences=sentences, size=EMBEDDING_DIM,\n",
        "    window=WINDOW, min_count=MIN_COUNT,\n",
        "    sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
        "print (w2v)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8z5jMCCrnKe",
        "outputId": "57b2cc79-cc07-4d51-ff9b-929f4d185d91"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec(vocab=4937, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector for each word\n",
        "w2v.wv.get_vector(\"potter\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKCLYceGr42y",
        "outputId": "53c657a9-5d1d-4f0b-fca7-eaa3f7599b5d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.634285  ,  0.4512361 ,  0.19600886,  0.3035163 ,  0.22624141,\n",
              "       -0.00562529,  0.31954873,  0.12425055,  0.04625868, -0.0803506 ,\n",
              "        0.28362238,  0.05348094,  0.04646057, -0.42759562,  0.27089566,\n",
              "        0.3085992 ,  0.26196435, -0.0753823 ,  0.05185913,  0.07407171,\n",
              "       -0.40631086,  0.00144508,  0.06667016, -0.21338981,  0.3173146 ,\n",
              "       -0.06946038,  0.2859973 , -0.02585209, -0.00683349, -0.08399896,\n",
              "       -0.28481162,  0.21456464, -0.17902794,  0.0655848 ,  0.08497088,\n",
              "        0.07355179,  0.03066273,  0.03188547, -0.2520867 ,  0.20940004,\n",
              "       -0.51192665,  0.06263869,  0.09805468, -0.00673292, -0.15904814,\n",
              "       -0.3227723 ,  0.29421997, -0.01934818,  0.02857134,  0.2314193 ,\n",
              "       -0.31512725, -0.05006034,  0.26197127, -0.43912706,  0.34179974,\n",
              "       -0.11335879, -0.11920541, -0.0675193 , -0.19508532,  0.09729342,\n",
              "        0.30996296,  0.26078704,  0.22522314,  0.02438541, -0.09704231,\n",
              "       -0.02194669, -0.6209023 , -0.22353896,  0.523804  , -0.06660156,\n",
              "        0.09043401,  0.04555508,  0.07157702, -0.31005445,  0.15288031,\n",
              "        0.14899155, -0.2845084 ,  0.14533982, -0.22548027,  0.48947012,\n",
              "       -0.26350027,  0.13461742,  0.36377254, -0.16832748,  0.15581658,\n",
              "       -0.2867379 , -0.10522037,  0.09325227, -0.17969272,  0.2719346 ,\n",
              "        0.01536843,  0.18077868, -0.34007242,  0.45437112, -0.10813189,\n",
              "        0.04887289, -0.28218672,  0.36392954, -0.76483583,  0.2614801 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "w2v.wv.most_similar(positive=\"scar\", topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiKb7ptNr-FI",
        "outputId": "745ea493-75b5-4a1a-9f9f-9e961f533141"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forehead', 0.9193440675735474),\n",
              " ('mouth', 0.9100075364112854),\n",
              " ('pain', 0.9068682193756104),\n",
              " ('prickling', 0.9038347005844116),\n",
              " ('throat', 0.9018400311470032)]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Saving and loading\n",
        "w2v.wv.save_word2vec_format(\"model.bin\", binary=True)\n",
        "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True)\n"
      ],
      "metadata": {
        "id": "DpneL0BwsxPX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##FastText\n",
        "What happens when a word doesn't exist in our vocabulary? We could assign an UNK token which is used for all OOV (out of vocabulary) words or we could use FastText, which uses character-level n-grams to embed a word. This helps embed rare words, misspelled words, and also words that don't exist in our corpus but are similar to words in our corpus."
      ],
      "metadata": {
        "id": "V6-f-KFHtQr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import FastText\n"
      ],
      "metadata": {
        "id": "JBS6yYq1s5NY"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Super fast because of optimized C code under the hood\n",
        "ft = FastText(sentences=sentences, size=EMBEDDING_DIM,\n",
        "              window=WINDOW, min_count=MIN_COUNT,\n",
        "              sg=SKIP_GRAM, negative=NEGATIVE_SAMPLING)\n",
        "print (ft)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdB7eDxttVUu",
        "outputId": "1d31f26d-812c-4d92-e979-246ffd935b9a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText(vocab=4937, size=100, alpha=0.025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This word doesn't exist so the word2vec model will error out\n",
        "w2v.wv.most_similar(positive=\"scarring\", topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "wgGrfboytYEC",
        "outputId": "74a6b888-f0d0-4463-e198-900f350e6743"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-974ef4ebc1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# This word doesn't exist so the word2vec model will error out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"scarring\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'scarring' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FastText will use n-grams to embed an OOV word\n",
        "ft.wv.most_similar(positive=\"scarring\", topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgeuAlHutiSp",
        "outputId": "37675496-4e89-48ee-c401-8a7b95afc82c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('shimmering', 0.9751896262168884),\n",
              " ('shivering', 0.9750393629074097),\n",
              " ('prickling', 0.9746742248535156),\n",
              " ('sparkling', 0.9741001129150391),\n",
              " ('coiling', 0.9716811180114746)]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and loading\n",
        "ft.wv.save(\"model.bin\")\n",
        "ft = KeyedVectors.load(\"model.bin\")\n"
      ],
      "metadata": {
        "id": "-pAbnxkUtlsJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pretrained embeddings\n",
        "We can learn embeddings from scratch using one of the approaches above but we can also leverage pretrained embeddings that have been trained on millions of documents. Popular ones include Word2Vec (skip-gram) or GloVe (global word-word co-occurrence). We can validate that these embeddings captured meaningful semantic relationships by confirming them."
      ],
      "metadata": {
        "id": "5jFOl_zrt1si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from urllib.request import urlopen\n",
        "from zipfile import ZipFile\n"
      ],
      "metadata": {
        "id": "I27IcNobtpBr"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Arguments\n",
        "EMBEDDING_DIM = 100\n"
      ],
      "metadata": {
        "id": "6-O7LqG4uAeg"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\n",
        "    for word in words:\n",
        "        index = embeddings.index2word.index(word)\n",
        "        plt.scatter(pca_results[index, 0], pca_results[index, 1])\n",
        "        plt.annotate(word, xy=(pca_results[index, 0], pca_results[index, 1]))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "T3S1OiICuDE0"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the file (may take ~3-5 minutes)\n",
        "resp = urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\")\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\n",
        "zipfile.namelist()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ5nBWzhuUWA",
        "outputId": "a4708d1f-27db-40fc-bddd-5e824ca8a908"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B.50d.txt',\n",
              " 'glove.6B.100d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.6B.300d.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write embeddings to file\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\n",
        "zipfile.extract(embeddings_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bzBRSIMluYwi",
        "outputId": "2ba9dddd-afea-4a9e-b26e-b158b0679b5d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/glove.6B.100d.txt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview of the GloVe embeddings file\n",
        "with open(embeddings_file, \"r\") as fp:\n",
        "    line = next(fp)\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    embedding = np.asarray(values[1:], dtype='float32')\n",
        "    print(line)\n",
        "    print(values)\n",
        "    print (f\"word: {word}\")\n",
        "    print (f\"embedding:\\n{embedding}\")\n",
        "    print (f\"embedding dim: {len(embedding)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LXva1jOu2nk",
        "outputId": "f9babb03-baf2-491a-aa06-c7e5670b7a8d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the -0.038194 -0.24487 0.72812 -0.39961 0.083172 0.043953 -0.39141 0.3344 -0.57545 0.087459 0.28787 -0.06731 0.30906 -0.26384 -0.13231 -0.20757 0.33395 -0.33848 -0.31743 -0.48336 0.1464 -0.37304 0.34577 0.052041 0.44946 -0.46971 0.02628 -0.54155 -0.15518 -0.14107 -0.039722 0.28277 0.14393 0.23464 -0.31021 0.086173 0.20397 0.52624 0.17164 -0.082378 -0.71787 -0.41531 0.20335 -0.12763 0.41367 0.55187 0.57908 -0.33477 -0.36559 -0.54857 -0.062892 0.26584 0.30205 0.99775 -0.80481 -3.0243 0.01254 -0.36942 2.2167 0.72201 -0.24978 0.92136 0.034514 0.46745 1.1079 -0.19358 -0.074575 0.23353 -0.052062 -0.22044 0.057162 -0.15806 -0.30798 -0.41625 0.37972 0.15006 -0.53212 -0.2055 -1.2526 0.071624 0.70565 0.49744 -0.42063 0.26148 -1.538 -0.30223 -0.073438 -0.28312 0.37104 -0.25217 0.016215 -0.017099 -0.38984 0.87424 -0.72569 -0.51058 -0.52028 -0.1459 0.8278 0.27062\n",
            "\n",
            "['the', '-0.038194', '-0.24487', '0.72812', '-0.39961', '0.083172', '0.043953', '-0.39141', '0.3344', '-0.57545', '0.087459', '0.28787', '-0.06731', '0.30906', '-0.26384', '-0.13231', '-0.20757', '0.33395', '-0.33848', '-0.31743', '-0.48336', '0.1464', '-0.37304', '0.34577', '0.052041', '0.44946', '-0.46971', '0.02628', '-0.54155', '-0.15518', '-0.14107', '-0.039722', '0.28277', '0.14393', '0.23464', '-0.31021', '0.086173', '0.20397', '0.52624', '0.17164', '-0.082378', '-0.71787', '-0.41531', '0.20335', '-0.12763', '0.41367', '0.55187', '0.57908', '-0.33477', '-0.36559', '-0.54857', '-0.062892', '0.26584', '0.30205', '0.99775', '-0.80481', '-3.0243', '0.01254', '-0.36942', '2.2167', '0.72201', '-0.24978', '0.92136', '0.034514', '0.46745', '1.1079', '-0.19358', '-0.074575', '0.23353', '-0.052062', '-0.22044', '0.057162', '-0.15806', '-0.30798', '-0.41625', '0.37972', '0.15006', '-0.53212', '-0.2055', '-1.2526', '0.071624', '0.70565', '0.49744', '-0.42063', '0.26148', '-1.538', '-0.30223', '-0.073438', '-0.28312', '0.37104', '-0.25217', '0.016215', '-0.017099', '-0.38984', '0.87424', '-0.72569', '-0.51058', '-0.52028', '-0.1459', '0.8278', '0.27062']\n",
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\n",
        "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFOwKgmhvXSA",
        "outputId": "29f8ff73-a965-4da8-d199-7522c5d90b16"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load embeddings (may take a minute)\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n"
      ],
      "metadata": {
        "id": "0jtjADSywk3D"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (king - man) + woman = ?\n",
        "# king - man = ? -  woman\n",
        "glove.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"], topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbBqfpmywxpB",
        "outputId": "478bd27b-cc88-4f55-c681-54d86e6ea3b7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438)]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get nearest neighbors (excluding itself)\n",
        "glove.wv.most_similar(positive=\"goku\", topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnkK-vFGxW0i",
        "outputId": "c2b1d9e2-9046-4135-9d9a-2d26920f3620"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gohan', 0.7246542572975159),\n",
              " ('bulma', 0.6497020125389099),\n",
              " ('raistlin', 0.6443604230880737),\n",
              " ('skaar', 0.6316742897033691),\n",
              " ('guybrush', 0.6231324672698975)]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce dimensionality for plotting\n",
        "X = glove[glove.wv.vocab]\n",
        "pca = PCA(n_components=2)\n",
        "pca_results = pca.fit_transform(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl-3YVWCxbUU",
        "outputId": "baa75432-58fa-4075-d550-59419bd0e900"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "plot_embeddings(\n",
        "    words=[\"king\", \"queen\", \"man\", \"woman\"], embeddings=glove,\n",
        "    pca_results=pca_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "x3OSvn2gxqR3",
        "outputId": "a00c87b0-7483-4f1b-962a-39af0d96631d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bias in embeddings\n",
        "glove.most_similar(positive=[\"woman\", \"doctor\"], negative=[\"man\"], topn=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3La02pLBxwz8",
        "outputId": "4b678a84-215a-4447-de18-562d3a76c911"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227346420288),\n",
              " ('physician', 0.7189429998397827),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750682592391968),\n",
              " ('dentist', 0.6726033687591553)]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up\n",
        "- Load data\n",
        "- preprocessing\n",
        "- Split data\n",
        "- Label encoding\n",
        "- Tokenizer\n",
        "\n",
        "Let's set our seed and device for our main task."
      ],
      "metadata": {
        "id": "FGS0ChcUsY_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "1w9z61PtyYp1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n"
      ],
      "metadata": {
        "id": "J8ZgHykVsqiR"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seeds(seed=1234):\n",
        "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # multi-GPU\n"
      ],
      "metadata": {
        "id": "eDgeEJz7stG1"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seeds for reproducibility\n",
        "set_seeds(seed=SEED)\n"
      ],
      "metadata": {
        "id": "BRl3lU8Etr-N"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "cuda = True\n",
        "device = torch.device(\"cuda\" if (\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
        "if device.type == \"cuda\":\n",
        "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
        "print (device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "begjBtHPtta0",
        "outputId": "71c4f97a-0283-4319-8360-59fe31161897"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load data\n",
        "We will download the AG News dataset, which consists of 120K text samples from 4 unique classes (Business, Sci/Tech, Sports, World)"
      ],
      "metadata": {
        "id": "8hPSpEXwuu-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/MadeWithML/main/datasets/news.csv\"\n",
        "df = pd.read_csv(url, header=0) # load\n",
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AHOBcFTNtxMc",
        "outputId": "900e5639-f43f-4a11-c14f-e7dd5d42af54"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc07db07-1c6e-4257-a7af-4c542dd1589f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc07db07-1c6e-4257-a7af-4c542dd1589f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc07db07-1c6e-4257-a7af-4c542dd1589f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc07db07-1c6e-4257-a7af-4c542dd1589f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocessing\n",
        "We're going to clean up our input data first by doing operations such as lower text, removing stop (filler) words, filters using regular expressions, etc."
      ],
      "metadata": {
        "id": "TmTNoj3mu3KA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n"
      ],
      "metadata": {
        "id": "xtCdJ6AYuy05"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "STOPWORDS = stopwords.words(\"english\")\n",
        "print (STOPWORDS[:5])\n",
        "porter = PorterStemmer() #Although not being used anywhere this is used to stem words to root word \n",
        "# eg: \"chocolatey\", \"choco\", \"chocolates\" get converted to chocolate\n",
        "# Some more example of stemming for root word \"like\" include:\n",
        "#\"likes\"\n",
        "#\"liked\"\n",
        "#\"likely\"\n",
        "#\"liking\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maXzAVsVvOYs",
        "outputId": "2655bd55-efa1-480f-a636-1d2a1d67e81a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess(text, stopwords=STOPWORDS):\n",
        "    \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\n",
        "    # Lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove stopwords\n",
        "    pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\n",
        "    text = pattern.sub(\"\", text)\n",
        "\n",
        "    # Remove words in parenthesis\n",
        "    text = re.sub(r\"\\([^)]*\\)\", \"\", text)\n",
        "\n",
        "    # Spacing and filters\n",
        "    text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\n",
        "    text = re.sub(\"[^A-Za-z0-9]+\", \" \", text) # remove non alphanumeric chars\n",
        "    text = re.sub(\" +\", \" \", text)  # remove multiple spaces\n",
        "    text = text.strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "lfGRGER7vkHJ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample\n",
        "text = \"Great week for the NYSE!\"\n",
        "preprocess(text=text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GDNy4OopwAyH",
        "outputId": "84a82ffc-5368-4cbe-ec7f-1271dce5c6ca"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'great week nyse'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply to dataframe\n",
        "preprocessed_df = df.copy()\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urkkdAUvwGhm",
        "outputId": "db6dbd4f-ff2b-46e6-ebbc-71f87dec19f4"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**Warning**\n",
        "\n",
        ">If you have preprocessing steps like standardization, etc. that are calculated, you need to separate the training and test set first before applying those operations. This is because we cannot apply any knowledge gained from the test set accidentally (data leak) during preprocessing/training. However for global preprocessing steps like the function above where we aren't learning anything from the data itself, we can perform before splitting the data\n",
        "\n",
        "##Split data\n"
      ],
      "metadata": {
        "id": "cP_vX8t-wP3k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "ZBOJlC8HwIe1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15\n"
      ],
      "metadata": {
        "id": "zXDwh3kFwfAT"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_test_split(X, y, train_size):\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
      ],
      "metadata": {
        "id": "WGXl4ADmwgUg"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "X = preprocessed_df[\"title\"].values\n",
        "y = preprocessed_df[\"category\"].values\n"
      ],
      "metadata": {
        "id": "mTqNx5E4whqv"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[0]}  {y_train[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-fTvhxwjCs",
        "outputId": "14600d71-70c2-4db0-a526-212297b0e78f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks  World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label encoding\n",
        "Next we'll define a LabelEncoder to encode our text labels into unique indices"
      ],
      "metadata": {
        "id": "JD2i-KaSwmmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n"
      ],
      "metadata": {
        "id": "62VhKEsgwklX"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelEncoder(object):\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\n",
        "    def __init__(self, class_to_index={}):\n",
        "        self.class_to_index = class_to_index or {}  # mutable defaults ;)\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.class_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\n",
        "\n",
        "    def fit(self, y):\n",
        "        classes = np.unique(y)\n",
        "        for i, class_ in enumerate(classes):\n",
        "            self.class_to_index[class_] = i\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\n",
        "        self.classes = list(self.class_to_index.keys())\n",
        "        return self\n",
        "\n",
        "    def encode(self, y):\n",
        "        encoded = np.zeros((len(y)), dtype=int)\n",
        "        for i, item in enumerate(y):\n",
        "            encoded[i] = self.class_to_index[item]\n",
        "        return encoded\n",
        "\n",
        "    def decode(self, y):\n",
        "        classes = []\n",
        "        for i, item in enumerate(y):\n",
        "            classes.append(self.index_to_class[item])\n",
        "        return classes\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {'class_to_index': self.class_to_index}\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ],
      "metadata": {
        "id": "bOLS7Fmpwo7-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(y_train)\n",
        "NUM_CLASSES = len(label_encoder)\n",
        "label_encoder.class_to_index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrnHiPbvxVYu",
        "outputId": "f777a773-cbbf-438a-b6d8-084ceb83cd88"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to tokens\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n",
        "y_train = label_encoder.encode(y_train)\n",
        "y_val = label_encoder.encode(y_val)\n",
        "y_test = label_encoder.encode(y_test)\n",
        "print (f\"y_train[0]: {y_train[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4173loGIxZV7",
        "outputId": "db53506a-d0d2-44a4-8fef-93a03fbff5e3"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class weights\n",
        "counts = np.bincount(y_train)\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-434Ly7xpAv",
        "outputId": "f2744d11-9bb1-45de-8135-a8ddf42640a8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenizer\n",
        "We'll define a Tokenizer to convert our text input data into token indices."
      ],
      "metadata": {
        "id": "n1_Aweaixu6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from more_itertools import take\n"
      ],
      "metadata": {
        "id": "S4qYmqAXxr08"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer(object):\n",
        "    def __init__(self, char_level, num_tokens=None,\n",
        "                 pad_token=\"<PAD>\", oov_token=\"<UNK>\",\n",
        "                 token_to_index=None):\n",
        "        self.char_level = char_level\n",
        "        self.separator = \"\" if self.char_level else \" \"\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\n",
        "        self.num_tokens = num_tokens\n",
        "        self.pad_token = pad_token\n",
        "        self.oov_token = oov_token\n",
        "        if not token_to_index:\n",
        "            token_to_index = {pad_token: 0, oov_token: 1}\n",
        "        self.token_to_index = token_to_index\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_index)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Tokenizer(num_tokens={len(self)})>\"\n",
        "\n",
        "    def fit_on_texts(self, texts):\n",
        "        if not self.char_level:\n",
        "            texts = [text.split(\" \") for text in texts]\n",
        "        all_tokens = [token for text in texts for token in text]\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\n",
        "        self.min_token_freq = counts[-1][1]\n",
        "        for token, count in counts:\n",
        "            index = len(self)\n",
        "            self.token_to_index[token] = index\n",
        "            self.index_to_token[index] = token\n",
        "        return self\n",
        "\n",
        "    def texts_to_sequences(self, texts):\n",
        "        sequences = []\n",
        "        for text in texts:\n",
        "            if not self.char_level:\n",
        "                text = text.split(\" \")\n",
        "            sequence = []\n",
        "            for token in text:\n",
        "                sequence.append(self.token_to_index.get(\n",
        "                    token, self.token_to_index[self.oov_token]))\n",
        "            sequences.append(np.asarray(sequence))\n",
        "        return sequences\n",
        "\n",
        "    def sequences_to_texts(self, sequences):\n",
        "        texts = []\n",
        "        for sequence in sequences:\n",
        "            text = []\n",
        "            for index in sequence:\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\n",
        "            texts.append(self.separator.join([token for token in text]))\n",
        "        return texts\n",
        "\n",
        "    def save(self, fp):\n",
        "        with open(fp, \"w\") as fp:\n",
        "            contents = {\n",
        "                \"char_level\": self.char_level,\n",
        "                \"oov_token\": self.oov_token,\n",
        "                \"token_to_index\": self.token_to_index\n",
        "            }\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls, fp):\n",
        "        with open(fp, \"r\") as fp:\n",
        "            kwargs = json.load(fp=fp)\n",
        "        return cls(**kwargs)\n"
      ],
      "metadata": {
        "id": "K9U19n4AxzxT"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Warning\n",
        "\n",
        ">It's important that we only fit using our train data split because during inference, our model will not always know every token so it's important to replicate that scenario with our validation and test splits as well."
      ],
      "metadata": {
        "id": "586qM_yP02vO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize\n",
        "tokenizer = Tokenizer(char_level=False, num_tokens=5000)\n",
        "tokenizer.fit_on_texts(texts=X_train)\n",
        "VOCAB_SIZE = len(tokenizer)\n",
        "print (tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfK6q-bm0zfA",
        "outputId": "9e1563bb-87ef-4788-8a25-35d515fd88da"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Tokenizer(num_tokens=5000)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample of tokens\n",
        "print (take(5, tokenizer.token_to_index.items()))\n",
        "print (f\"least freq token's freq: {tokenizer.min_token_freq}\") # use this to adjust num_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrXB3kz400eF",
        "outputId": "96c8801c-556a-4941-c248-e01f55211ffe"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert texts to sequences of indices\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_val = tokenizer.texts_to_sequences(X_val)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "preprocessed_text = tokenizer.sequences_to_texts([X_train[0]])[0]\n",
        "print (\"Text to indices:\\n\"\n",
        "    f\"  (preprocessed)  {preprocessed_text}\\n\"\n",
        "    f\"  (tokenized)  {X_train[0]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxoAU6ld00hu",
        "outputId": "c75b339e-a199-4498-ddf3-c84fc12fd14e"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text to indices:\n",
            "  (preprocessed)  china battles north korea nuclear talks\n",
            "  (tokenized)  [  16 1491  285  142  114   24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Embedding layer\n",
        "We can embed our inputs using PyTorch's embedding layer.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X9FS7ZCD0_sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input\n",
        "vocab_size = 10\n",
        "x = torch.randint(high=vocab_size, size=(1,5))\n",
        "print (x)\n",
        "print (x.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQrfka-000km",
        "outputId": "00196909-449f-4e25-e6b5-72e843c205f6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 6, 5, 2, 6]])\n",
            "torch.Size([1, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding layer\n",
        "embeddings = nn.Embedding(embedding_dim=100, num_embeddings=vocab_size)\n",
        "print (embeddings.weight.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao1FCpYd00m7",
        "outputId": "985b631a-2683-42b3-dfc2-0fb51cd296e7"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed the input\n",
        "embeddings(x).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66a37a-a00pS",
        "outputId": "5b7738e7-ac0c-4e9b-8cef-3e995bdf8449"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SDqyyZYt15nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each token in the input is represented via embeddings (all out-of-vocabulary (OOV) tokens are given the embedding for UNK token.) In the model below, we'll see how to set these embeddings to be pretrained GloVe embeddings and how to choose whether to freeze (fixed embedding weights) those embeddings or not during training."
      ],
      "metadata": {
        "id": "L-qcTkOV15vT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Padding\n",
        "Our inputs are all of varying length but we need each batch to be uniformly shaped. Therefore, we will use padding to make all the inputs in the batch the same length. Our padding index will be 0 (note that this is consistent with the <PAD> token defined in our Tokenizer).\n",
        "\n",
        ">While embedding our input tokens will create a batch of shape (N, max_seq_len, embed_dim) we only need to provide a 2D matrix (N, max_seq_len) for using embeddings with PyTorch."
      ],
      "metadata": {
        "id": "2eVmXnuD2AHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequences(sequences, max_seq_len=0):\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        padded_sequences[i][:len(sequence)] = sequence\n",
        "    return padded_sequences\n"
      ],
      "metadata": {
        "id": "NHGdQusl00rp"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2D sequences\n",
        "padded = pad_sequences(X_train[0:3])\n",
        "print (padded.shape)\n",
        "print (padded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Mf6qMD3Rzs",
        "outputId": "12eebcdc-cc28-44e4-d2ff-3e8c25ba91bc"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 6)\n",
            "[[1.600e+01 1.491e+03 2.850e+02 1.420e+02 1.140e+02 2.400e+01]\n",
            " [1.445e+03 2.300e+01 6.560e+02 2.197e+03 1.000e+00 0.000e+00]\n",
            " [1.200e+02 1.400e+01 1.955e+03 1.005e+03 1.529e+03 4.014e+03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset\n",
        "We're going to create Datasets and DataLoaders to be able to efficiently create batches with our data splits."
      ],
      "metadata": {
        "id": "H8PugnPT4sXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams\n",
        "print(FILTER_SIZES)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzGKo9-93skQ",
        "outputId": "fd7b81f2-b3f5-4a1a-c1bf-674ebe9af809"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, max_filter_size):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.max_filter_size = max_filter_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"<Dataset(N={len(self)})>\"\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index]\n",
        "        y = self.y[index]\n",
        "        return [X, y]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        \"\"\"Processing on a batch.\"\"\"\n",
        "        # Get inputs\n",
        "        batch = np.array(batch)\n",
        "        X = batch[:, 0]\n",
        "        y = batch[:, 1]\n",
        "\n",
        "        # Pad sequences\n",
        "        X = pad_sequences(X)\n",
        "\n",
        "        # Cast\n",
        "        X = torch.LongTensor(X.astype(np.int32))\n",
        "        y = torch.LongTensor(y.astype(np.int32))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\n",
        "        return torch.utils.data.DataLoader(\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "gCdxFC0v45n3"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "max_filter_size = max(FILTER_SIZES)\n",
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\n",
        "print (\"Datasets:\\n\"\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\n",
        "    \"Sample point:\\n\"\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\n",
        "    f\"  y: {train_dataset[0][1]}\")\n",
        "# Notice the padding is happening inside the batch collate function. So unless we iter on dataloader in batch. The above output is simply by calling the get_item method."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MC3cLhc5LZH",
        "outputId": "11ec6993-625a-451c-aeb2-9deb174702dc"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [  16 1491  285  142  114   24]\n",
            "  y: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders\n",
        "batch_size = 64\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\n",
        "\n",
        "c=0\n",
        "for batch_X, batch_y in iter(train_dataloader):\n",
        "  c+=1\n",
        "  if c>5:\n",
        "    break\n",
        "  # batch_X, batch_y = next(iter(train_dataloader))\n",
        "  print (\"Sample batch:\\n\"\n",
        "      f\"  X: {list(batch_X.size())}\\n\"\n",
        "      f\"  y: {list(batch_y.size())}\\n\"\n",
        "      \"Sample point:\\n\"\n",
        "      f\"  X: {batch_X[0]}\\n\"\n",
        "      f\"  y: {batch_y[0]}\")\n",
        "\n",
        "# As you can see we are having same size throughout a batch but different sizes among different batches.\n",
        "# This is due to the fact that collate function is taking max_len of seq in that batch."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH5KdMwQ5Vpc",
        "outputId": "4d2d54a4-2586-42ff-dd33-280664b10df3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "  X: [64, 14]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([  16, 1491,  285,  142,  114,   24,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0], device='cpu')\n",
            "  y: 3\n",
            "Sample batch:\n",
            "  X: [64, 14]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([1028,    1,  477,    1,  755,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0], device='cpu')\n",
            "  y: 2\n",
            "Sample batch:\n",
            "  X: [64, 15]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([1175, 4023,    1,  344, 2355,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0], device='cpu')\n",
            "  y: 0\n",
            "Sample batch:\n",
            "  X: [64, 9]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([4365, 2588, 1228,  725,    0,    0,    0,    0,    0], device='cpu')\n",
            "  y: 2\n",
            "Sample batch:\n",
            "  X: [64, 15]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([   1, 1272,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0], device='cpu')\n",
            "  y: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model\n",
        "We'll be using a convolutional neural network on top of our embedded tokens to extract meaningful spatial signal. This time, we'll be using many filter widths to act as n-gram feature extractors.\n",
        "\n",
        "Let's visualize the model's forward pass.\n",
        "\n",
        "- We'll first tokenize our inputs (batch_size, max_seq_len).\n",
        "- Then we'll embed our tokenized inputs (batch_size, max_seq_len, embedding_dim).\n",
        "- We'll apply convolution via filters (filter_size, embedding_dim, num_filters) followed by batch normalization. Our filters act as character level n-gram detectors. We have three different filter sizes (2, 3 and 4) and they will act as bi-gram, tri-gram and 4-gram feature extractors, respectively.\n",
        "- We'll apply 1D global max pooling which will extract the most relevant information from the feature maps for making the decision.\n",
        "- We feed the pool outputs to a fully-connected (FC) layer (with dropout).\n",
        "- We use one more FC layer with softmax to derive class probabilities.\n",
        "\n",
        "<img src='https://madewithml.com/static/images/foundations/embeddings/model.png'>"
      ],
      "metadata": {
        "id": "PSzVBztV7iR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "7tmPOypm6jh_"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 100\n",
        "DROPOUT_P = 0.1\n"
      ],
      "metadata": {
        "id": "tcfW1EJ_-WZd"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
        "                 padding_idx=0):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Filter sizes\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        # Initialize embeddings\n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
        "\n",
        "        # Freeze embeddings or not\n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Conv outputs\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # `SAME` padding\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv + pool\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "            _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\n",
        "            z.append(_z)\n",
        "\n",
        "        # Concat conv outputs\n",
        "        z = torch.cat(z, 1)\n",
        "\n",
        "        # FC layers\n",
        "        z = self.fc1(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.fc2(z)\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "6pvB3sf6-Yia"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using GloVe\n",
        "We're going create some utility functions to be able to load the pretrained GloVe embeddings into our Embeddings layer."
      ],
      "metadata": {
        "id": "Lh3eK2XY_IKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_glove_embeddings(embeddings_file):\n",
        "    \"\"\"Load embeddings from a file.\"\"\"\n",
        "    embeddings = {}\n",
        "    with open(embeddings_file, \"r\") as fp:\n",
        "        for index, line in enumerate(fp):\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            embedding = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = embedding\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "_KD_i-QX_Ekp"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\n",
        "    \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_index), embedding_dim))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix\n"
      ],
      "metadata": {
        "id": "Sh299QYP_Nze"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings\n",
        "embeddings_file = 'glove.6B.{0}d.txt'.format(EMBEDDING_DIM)\n",
        "glove_embeddings = load_glove_embeddings(embeddings_file=embeddings_file)\n",
        "embedding_matrix = make_embeddings_matrix(\n",
        "    embeddings=glove_embeddings, word_index=tokenizer.token_to_index,\n",
        "    embedding_dim=EMBEDDING_DIM)\n",
        "print (f\"<Embeddings(words={embedding_matrix.shape[0]}, dim={embedding_matrix.shape[1]})>\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlxlEviO_k69",
        "outputId": "1f6639b8-1f82-4401-d379-3463946b3a34"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Embeddings(words=5000, dim=100)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Experiments\n",
        "We have first have to decide whether to use pretrained embeddings randomly initialized ones. Then, we can choose to freeze our embeddings or continue to train them using the supervised data (this could lead to overfitting). Here are the three experiments we're going to conduct:\n",
        "\n",
        "- randomly initialized embeddings (fine-tuned)\n",
        "- GloVe embeddings (frozen)\n",
        "- GloVe embeddings (fine-tuned)"
      ],
      "metadata": {
        "id": "vU8s8Z9TAJjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from torch.optim import Adam\n"
      ],
      "metadata": {
        "id": "Z-cLReyBAC9X"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FILTERS = 50\n",
        "LEARNING_RATE = 1e-3\n",
        "PATIENCE = 5\n",
        "NUM_EPOCHS = 10\n"
      ],
      "metadata": {
        "id": "hEnCnp9EAoIy"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Trainer(object):\n",
        "    def __init__(self, model, device, loss_fn=None, optimizer=None, scheduler=None):\n",
        "\n",
        "        # Set params\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.loss_fn = loss_fn\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def train_step(self, dataloader):\n",
        "        \"\"\"Train step.\"\"\"\n",
        "        # Set model to train mode\n",
        "        self.model.train()\n",
        "        loss = 0.0\n",
        "\n",
        "        # Iterate over train batches\n",
        "        for i, batch in enumerate(dataloader):\n",
        "\n",
        "            # Step\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\n",
        "            inputs, targets = batch[:-1], batch[-1]\n",
        "            self.optimizer.zero_grad()  # Reset gradients\n",
        "            z = self.model(inputs)  # Forward pass\n",
        "            J = self.loss_fn(z, targets)  # Define loss\n",
        "            J.backward()  # Backward pass\n",
        "            self.optimizer.step()  # Update weights\n",
        "\n",
        "            # Cumulative Metrics\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def eval_step(self, dataloader):\n",
        "        \"\"\"Validation or test step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        loss = 0.0\n",
        "        y_trues, y_probs = [], []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Step\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\n",
        "                inputs, y_true = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)  # Forward pass\n",
        "                J = self.loss_fn(z, y_true).item()\n",
        "\n",
        "                # Cumulative Metrics\n",
        "                loss += (J - loss) / (i + 1)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "                y_trues.extend(y_true.cpu().numpy())\n",
        "\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\n",
        "\n",
        "    def predict_step(self, dataloader):\n",
        "        \"\"\"Prediction step.\"\"\"\n",
        "        # Set model to eval mode\n",
        "        self.model.eval()\n",
        "        y_probs = []\n",
        "\n",
        "        # Iterate over val batches\n",
        "        with torch.inference_mode():\n",
        "            for i, batch in enumerate(dataloader):\n",
        "\n",
        "                # Forward pass w/ inputs\n",
        "                inputs, targets = batch[:-1], batch[-1]\n",
        "                z = self.model(inputs)\n",
        "\n",
        "                # Store outputs\n",
        "                y_prob = F.softmax(z).cpu().numpy()\n",
        "                y_probs.extend(y_prob)\n",
        "\n",
        "        return np.vstack(y_probs)\n",
        "\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\n",
        "        best_val_loss = np.inf\n",
        "        for epoch in range(num_epochs):\n",
        "            # Steps\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\n",
        "            self.scheduler.step(val_loss)\n",
        "\n",
        "            # Early stopping\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = self.model\n",
        "                _patience = patience  # reset _patience\n",
        "            else:\n",
        "                _patience -= 1\n",
        "            if not _patience:  # 0\n",
        "                print(\"Stopping early!\")\n",
        "                break\n",
        "\n",
        "            # Logging\n",
        "            print(\n",
        "                f\"Epoch: {epoch+1} | \"\n",
        "                f\"train_loss: {train_loss:.5f}, \"\n",
        "                f\"val_loss: {val_loss:.5f}, \"\n",
        "                f\"lr: {self.optimizer.param_groups[0]['lr']:.2E}, \"\n",
        "                f\"_patience: {_patience}\"\n",
        "            )\n",
        "        return best_model\n"
      ],
      "metadata": {
        "id": "uwtmCJ4fAqBc"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(y_true, y_pred, classes):\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\n",
        "    # Performance\n",
        "    performance = {\"overall\": {}, \"class\": {}}\n",
        "\n",
        "    # Overall performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    performance[\"overall\"][\"precision\"] = metrics[0]\n",
        "    performance[\"overall\"][\"recall\"] = metrics[1]\n",
        "    performance[\"overall\"][\"f1\"] = metrics[2]\n",
        "    performance[\"overall\"][\"num_samples\"] = np.float64(len(y_true))\n",
        "\n",
        "    # Per-class performance\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
        "    for i in range(len(classes)):\n",
        "        performance[\"class\"][classes[i]] = {\n",
        "            \"precision\": metrics[0][i],\n",
        "            \"recall\": metrics[1][i],\n",
        "            \"f1\": metrics[2][i],\n",
        "            \"num_samples\": np.float64(metrics[3][i]),\n",
        "        }\n",
        "\n",
        "    return performance\n"
      ],
      "metadata": {
        "id": "cZ2DZllQBHph"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random initialization"
      ],
      "metadata": {
        "id": "RO4MA4UCBNyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_EMBEDDINGS = None\n",
        "FREEZE_EMBEDDINGS = False\n"
      ],
      "metadata": {
        "id": "3kbDw4-uBLP4"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUfrFIzSBQio",
        "outputId": "c23cb5c2-784e-4d4b-827c-f481888f3653"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ],
      "metadata": {
        "id": "bK1UN78RBSR9"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)\n"
      ],
      "metadata": {
        "id": "Wow24UB6BUyO"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)\n"
      ],
      "metadata": {
        "id": "WOE1C0EABWgv"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCNjpbNuBaDO",
        "outputId": "a5df7e35-cb92-4e98-d138-09c9e2f7b0de"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.76917, val_loss: 0.60189, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.49284, val_loss: 0.56432, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.40431, val_loss: 0.57742, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.34308, val_loss: 0.60263, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.29424, val_loss: 0.64922, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.25348, val_loss: 0.67969, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBlzhLA_Bbz1",
        "outputId": "f9d73330-6dab-4dfd-a17e-37b8d29ec6aa"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY593hvVBjuA",
        "outputId": "03243e05-4692-43d1-ae75-874dc888569d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.8100623525903646,\n",
            "  \"recall\": 0.8081666666666667,\n",
            "  \"f1\": 0.8086877631986215,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Glove (frozen)"
      ],
      "metadata": {
        "id": "ZYXtzpk0B0eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
        "FREEZE_EMBEDDINGS = True\n"
      ],
      "metadata": {
        "id": "xxPgN67oBnLo"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIl0GsWoCgxL",
        "outputId": "40a2b186-5332-4d30-dc41-4fde243c79d2"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ],
      "metadata": {
        "id": "Kn6f9dqbCy24"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)\n"
      ],
      "metadata": {
        "id": "IMzA7j48C5Yg"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)\n"
      ],
      "metadata": {
        "id": "uj9T2euAC7lj"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwxEhP3-C_lx",
        "outputId": "7e15e174-7aed-40b9-9857-593512a1625a"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.51432, val_loss: 0.47329, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.44300, val_loss: 0.46209, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.41174, val_loss: 0.46395, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.38683, val_loss: 0.46741, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.36753, val_loss: 0.47525, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.35120, val_loss: 0.48571, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HP5XapzWDC7P",
        "outputId": "90d113f9-98d5-47cf-f22d-97901b19e342"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_WdT4aDFYu",
        "outputId": "fd66c70a-262e-4482-9aa1-343fd09162ab"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.8337198748275664,\n",
            "  \"recall\": 0.8331111111111111,\n",
            "  \"f1\": 0.8331056129077398,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Glove (fine-tuned)"
      ],
      "metadata": {
        "id": "_IocOAMVDJ5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
        "FREEZE_EMBEDDINGS = False\n"
      ],
      "metadata": {
        "id": "zEY2xSlXDHtv"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model = model.to(device) # set device\n",
        "print (model.named_parameters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgkQ1WZkDP_-",
        "outputId": "ecdb0556-a050-4176-a6cb-55909b193fa9"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Loss\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ],
      "metadata": {
        "id": "SqjUX8TaDR_U"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define optimizer & scheduler\n",
        "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode=\"min\", factor=0.1, patience=3)\n"
      ],
      "metadata": {
        "id": "0kVlaRSDDT45"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer module\n",
        "trainer = Trainer(\n",
        "    model=model, device=device, loss_fn=loss_fn,\n",
        "    optimizer=optimizer, scheduler=scheduler)\n"
      ],
      "metadata": {
        "id": "T3N41YxVDWNI"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "best_model = trainer.train(\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4B577i0KDYWX",
        "outputId": "3ed4e453-fc5a-4fe9-a050-8fa50ed7e4c2"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.48843, val_loss: 0.44549, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.39052, val_loss: 0.44479, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.34396, val_loss: 0.46035, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.30118, val_loss: 0.49217, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.25584, val_loss: 0.54880, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.21283, val_loss: 0.62450, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fof9Nm5eDaxj",
        "outputId": "92868007-e23e-44cf-9c3b-eab1401f485a"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine performance\n",
        "performance = get_metrics(\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\n",
        "print (json.dumps(performance[\"overall\"], indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sJGXVjXDcyb",
        "outputId": "55c83c27-7bf3-420d-cee6-51edfb79ff06"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"precision\": 0.8261934002672031,\n",
            "  \"recall\": 0.8256666666666667,\n",
            "  \"f1\": 0.8258438620643749,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save artifacts\n",
        "from pathlib import Path\n",
        "dir = Path(\"cnn\")\n",
        "dir.mkdir(parents=True, exist_ok=True)\n",
        "label_encoder.save(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer.save(fp=Path(dir, \"tokenizer.json\"))\n",
        "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\n",
        "with open(Path(dir, \"performance.json\"), \"w\") as fp:\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)\n"
      ],
      "metadata": {
        "id": "KOas-DXnDetK"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ],
      "metadata": {
        "id": "1aSmnS1yDnWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probability_distribution(y_prob, classes):\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\n",
        "    results = {}\n",
        "    for i, class_ in enumerate(classes):\n",
        "        results[class_] = np.float64(y_prob[i])\n",
        "    sorted_results = {k: v for k, v in sorted(\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\n",
        "    return sorted_results\n"
      ],
      "metadata": {
        "id": "rNvX9VOvDi3Y"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load artifacts\n",
        "device = torch.device(\"cpu\")\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, \"label_encoder.json\"))\n",
        "tokenizer = Tokenizer.load(fp=Path(dir, \"tokenizer.json\"))\n",
        "model = CNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XUHKg9hDqtO",
        "outputId": "7d67cc6b-ef30-4500-989b-c6df3e1bd20a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(model=model, device=device)\n"
      ],
      "metadata": {
        "id": "zLnbhBUcD_yw"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader\n",
        "text = \"The final tennis tournament starts next week.\"\n",
        "X = tokenizer.texts_to_sequences([preprocess(text)])\n",
        "print (tokenizer.sequences_to_texts(X))\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La55XqBfEChy",
        "outputId": "9c11332b-c1fe-44da-97c0-1e4b64ef666e"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['final tennis tournament starts next week']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "y_prob = trainer.predict_step(dataloader)\n",
        "y_pred = np.argmax(y_prob, axis=1)\n",
        "label_encoder.decode(y_pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4XuoVVEERaY",
        "outputId": "999b199f-f05b-418f-b160-c545d06e27d5"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:76: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sports']"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Class distributions\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\n",
        "print (json.dumps(prob_dist, indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LE7S_0ibEbY7",
        "outputId": "cef42a3f-a771-4eec-9c05-0e1413251bc9"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sports\": 1.0,\n",
            "  \"World\": 1.8838646198560127e-08,\n",
            "  \"Sci/Tech\": 5.417130632956457e-10,\n",
            "  \"Business\": 8.433008523260621e-13\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interpretability\n",
        "We went through all the trouble of padding our inputs before convolution to result is outputs of the same shape as our inputs so we can try to get some interpretability. Since every token is mapped to a convolutional output on which we apply max pooling, we can see which token's output was most influential towards the prediction. We first need to get the conv outputs from our model:"
      ],
      "metadata": {
        "id": "bfkB4q2dEnhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "ez1jtJb-EeTV"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InterpretableCNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\n",
        "                 padding_idx=0):\n",
        "        super(InterpretableCNN, self).__init__()\n",
        "\n",
        "        # Filter sizes\n",
        "        self.filter_sizes = filter_sizes\n",
        "\n",
        "        # Initialize embeddings\n",
        "        if pretrained_embeddings is None:\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx)\n",
        "        else:\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\n",
        "            self.embeddings = nn.Embedding(\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\n",
        "\n",
        "        # Freeze embeddings or not\n",
        "        if freeze_embeddings:\n",
        "            self.embeddings.weight.requires_grad = False\n",
        "\n",
        "        # Conv weights\n",
        "        self.conv = nn.ModuleList(\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\n",
        "                       out_channels=num_filters,\n",
        "                       kernel_size=f) for f in filter_sizes])\n",
        "\n",
        "        # FC weights\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, inputs, channel_first=False):\n",
        "\n",
        "        # Embed\n",
        "        x_in, = inputs\n",
        "        x_in = self.embeddings(x_in)\n",
        "\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\n",
        "        if not channel_first:\n",
        "            x_in = x_in.transpose(1, 2)\n",
        "\n",
        "        # Conv outputs\n",
        "        z = []\n",
        "        max_seq_len = x_in.shape[2]\n",
        "        for i, f in enumerate(self.filter_sizes):\n",
        "            # `SAME` padding\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\n",
        "\n",
        "            # Conv + pool\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\n",
        "            z.append(_z.cpu().numpy())\n",
        "\n",
        "        return z\n"
      ],
      "metadata": {
        "id": "EEc4RR8_ErEz"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\n",
        "FREEZE_EMBEDDINGS = False\n"
      ],
      "metadata": {
        "id": "y6JLPUbfE19r"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "interpretable_model = InterpretableCNN(\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, \"model.pt\"), map_location=device))\n",
        "interpretable_model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZg2PpcaE52Q",
        "outputId": "4c72d028-a360-4fe6-fea0-13e854c3540e"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get conv outputs\n",
        "interpretable_model.eval()\n",
        "conv_outputs = []\n",
        "with torch.inference_mode():\n",
        "    for i, batch in enumerate(dataloader):\n",
        "\n",
        "        # Forward pass w/ inputs\n",
        "        inputs, targets = batch[:-1], batch[-1]\n",
        "        z = interpretable_model(inputs)\n",
        "\n",
        "        # Store conv outputs\n",
        "        conv_outputs.extend(z)\n",
        "\n",
        "conv_outputs = np.vstack(conv_outputs)\n",
        "print (conv_outputs.shape) # (len(filter_sizes), num_filters, max_seq_len)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSEPftFrE7zK",
        "outputId": "d6b0301e-15de-4de1-ba06-2490ed8c8424"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 50, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a bi-gram filter's outputs\n",
        "tokens = tokenizer.sequences_to_texts(X)[0].split(\" \")\n",
        "filter_size = 2\n",
        "sns.heatmap(conv_outputs[filter_size-1], xticklabels=tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "0HX4DidwE-R2",
        "outputId": "9d9bb1f1-bb0a-4b21-8b6a-8771713ab8ad"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcfa1e1ff90>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1D global max-pooling would extract the highest value from each of our num_filters for each filter_size. We could also follow this same approach to figure out which n-gram is most relevant but notice in the heatmap above that many filters don't have much variance. To mitigate this, this paper uses threshold values to determine which filters to use for interpretability. But to keep things simple, let's extract which tokens' filter outputs were extracted via max-pooling the most frequenctly."
      ],
      "metadata": {
        "id": "b2APe9VPFqn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = 0\n",
        "print (f\"Original text:\\n{text}\")\n",
        "print (f\"\\nPreprocessed text:\\n{tokenizer.sequences_to_texts(X)[0]}\")\n",
        "print (\"\\nMost important n-grams:\")\n",
        "# Process conv outputs for each unique filter size\n",
        "for i, filter_size in enumerate(FILTER_SIZES):\n",
        "\n",
        "    # Identify most important n-gram (excluding last token)\n",
        "    popular_indices = collections.Counter([np.argmax(conv_output) \\\n",
        "            for conv_output in conv_outputs[i]])\n",
        "\n",
        "    # Get corresponding text\n",
        "    start = popular_indices.most_common(1)[-1][0]\n",
        "    n_gram = \" \".join([token for token in tokens[start:start+filter_size]])\n",
        "    print (f\"[{filter_size}-gram]: {n_gram}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M39ukyYFA3q",
        "outputId": "e7bfed0d-5f93-4cb4-8171-9bb711034d60"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "The final tennis tournament starts next week.\n",
            "\n",
            "Preprocessed text:\n",
            "final tennis tournament starts next week\n",
            "\n",
            "Most important n-grams:\n",
            "[1-gram]: tennis\n",
            "[2-gram]: final tennis\n",
            "[3-gram]: final tennis tournament\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OC0sw0odGYdt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}